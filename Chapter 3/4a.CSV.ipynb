{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV \n",
    "\n",
    "Comma-separated values is a common data storage format. Yet, despite it's name it is actually an amalgam of a variety of possible formats, some of which do not even use commas as separators! Rather, when I say CSV here I'm referring to data that is stored in a rectangular format, with rows, columns, and often headers. Such data is extremely common on the web when looking for data sets. However, lots of tables vary in their specification. Here are some important features to consider:\n",
    "\n",
    "- **Headers**: Does the file have headers for the columns? In the pandas ```pd.read_csv()``` method (or Python's built-in ```csvreader```) you can indicate that the file has a header with the ```headers=True``` argument. In neither case, however, does it deal nicely with two line headers. IF you have a two line header, you might be better off reading the file in and then writing the file back line by line but excluding the first line. Then using this new file, you would import it as usual.\n",
    "- **Quote character**: The quote character is used to indicate that all of the text inside quotes refers to one string. This is important in the cases where you are parsing a comma-separated file, but the file has commas in it. For example, imagine a file of addresses with headers: Name, Location, User. Now imagine one line of data is \"Drake, Toronto, Canada, False\". It might parse that as ```Name: Drake```, ```Location: Toronto```, ```User: Canada```, followed by a parse error. If the data, on the other hand was: \n",
    "\n",
    "~~~\n",
    "Drake, \"Toronto, Canada\", False \n",
    "~~~\n",
    "\n",
    "Then it is clear that the comma in between Toronto and Canada belongs in the string. Now you might be wondering what if you want to use the quote character in the string? This is where we would use 'escape codes'. In this case using \\\" to include \" inside a string. See this entry for an example:\n",
    "\n",
    "~~~ \n",
    "Name, Location, User\n",
    "\"Sean \\\"P. Diddy\\\" Combs\", \"New York City, NY\", False\n",
    "~~~\n",
    "\n",
    "- **Delimiter**: Even though it is a comma separated file, sometimes people will use a different way of making the separation. A common option is the tab character (and sometimes it is even referred to as a TSV or Tab-separated values\".\n",
    "- **New Lines**: There are two issues with new lines that sometimes trip people up. The first is that, particularly on some old files, the end of a file has a ```\\r\\n``` rather than just an ```\\n```. This is because the ```\\r``` represents a 'return carriage', that is , the cursor should go down one line and return to the left of the screen. This is very similar to a typewriter. Thankfully it is now really rare and almost all CSV files use ```\\n```. The second issue is how many ```\\n``` characters are at the bottom. Sometimes if there is more than one the computer gets confused because in between them it would expect a full row.  \n",
    "\n",
    "It is not difficult to build your own CSV parser. In fact, that is one of the exercises in this section. However, it is clear that there are enough little details to attend to that it makes sense to use the build in packages where possible. Python offers two main ways to parse CSV files. First is the ```csv``` library. This is a standalone library that can be imported. It has many options for separators and whether there's a header. It also has some nice ways to index the data. For example, if you want to store your data as a dictionary with the header as the key and the column as the values, you can use ```csvreader``` to do that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the build-in CSVReader \n",
    "The basic usage, however, is to iterate through a file line by line. Instead of iterating through with 'readline' and splitting the text that comes back, you create a \"csv reader\", and this iterates line by line returning not a string of text, but a list split at every comma (or user-defined separator). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿Name               Gender              Species             First Appearance    \n",
      "Fozzie              Male                Bear                1976                \n",
      "Kermit              Male                Frog                1955                \n",
      "Piggy               Female              Pig                 1974                \n",
      "Gonzo               Male                Unknown             1970                \n",
      "Rowlf               Male                Dog                 1962                \n",
      "Beaker              Male                Muppet              1977                \n",
      "Janice              Female              Muppet              1975                \n",
      "Hilda               Female              Muppet              1976                \n"
     ]
    }
   ],
   "source": [
    "import csv,os\n",
    "\n",
    "with open('..{0}Data{0}MuppetsTable.csv'.format(os.sep), newline='') as file_to_read:\n",
    "    filereader = csv.reader(file_to_read, delimiter=',', quotechar='|')\n",
    "    for row in filereader:\n",
    "        row = [\"{:<20}\".format(x) for x in row]\n",
    "        print(\"\".join(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about ```csv```, particularly when not using pandas, is the use of the DictReader. This returns a dictionary with the header as the key and the values in that row as the value. If there's no header line, you can specify a list to be the keys using the ```fieldnames``` argument, such as ```fieldnames = [\"Name\",\"Location\",\"User\"].``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Pandas CSV reader \n",
    "To import into a DataFrame directly using pandas, observe: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('..{0}Data{0}MuppetsTable.csv'.format(os.sep)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the CSVReader, the pandas ```pd.read_csv``` method has many arguments for things like headers and delimiters. \n",
    "\n",
    "> TIP: **Using help()** \n",
    ">\n",
    "> You can use help in jupyter or in a python console by encasing any method or function in ```help()```. So to learn about all the arguments for read_csv, you would run help(pd.read_csv). A word of caution: Note that this is without the ```()``` after ```read_csv```. If you put those parentheses inside the help method, then it will first _evaluate_ ```read_csv()``` which means you will be asking for help on whatever ```read_csv()``` returns, not on ```read_csv``` the method itself. \n",
    "\n",
    "Since we will almost always be moving data to a DataFrame this is often a very handy thing to get working. However, as data gets larger, reading straight into a DataFrame gets increasingly slow. For very massive files you might want to read them piecemeal. How large are we talking? On modern computers we might be talking CSVs in the hundreds of megabytes or more. Below that, Python should be very speedy importing and parsing CSVs. Above that and you will want to consider whether to just read in parts of the file at a time or another strategy, typically to divide and conqueror the data. For really big data (on the order of gigabytes or more, where you will have more data than RAM) you will want to turn to server-based solutions outside of scope in this book, such as Google's BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
